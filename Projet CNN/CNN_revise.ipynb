{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Les imports ici\n",
    "\n",
    "import os #Permet d'acceder au csv\n",
    "\n",
    "import pandas as pd #Lire csv, \n",
    "\n",
    "import unicodedata #pour checker comment sont les charactères\n",
    "\n",
    "import torch \n",
    "\n",
    "from PIL import Image #Dans le __getitem__ du dataset pour ouvrir l'image dans le dataset\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset #Pour créer les train/test_loader et le dataset lié au image/artistes\n",
    "\n",
    "import torchvision.transforms as transforms #pour la transformation utiliser du a notre pre-tained model\n",
    "\n",
    "from torchvision import models #Va nous servir a recup le model resNet50 pré-entrainé\n",
    "\n",
    "import torch.nn as nn #Va nous servir a remplacer la dernière couche du modèle par le nombre de classe qu'on veut en sorti (le nb d'artiste)\n",
    "\n",
    "from tqdm import tqdm #Utile pour voir la progression de l'entrainement\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder #Pour convertir les tuples en tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On essaiera d'affiné le résultat de notre CNN sans se soucié du modèle pré-entrainer utilisé pour le moment.\n",
    "\n",
    "##### Pour le première essais On utilise la donnée comme tel __SANS data-augmentation__\n",
    "##### Model pré-entrainer: __resNet50__\n",
    "##### On utilise uniquement le __nom__ de nos artistes lors de ce premier essais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Amedeo_Modigliani', 'Vasiliy_Kandinskiy', 'Diego_Rivera', 'Claude_Monet', 'Rene_Magritte', 'Salvador_Dali', 'Edouard_Manet', 'Andrei_Rublev', 'Vincent_van_Gogh', 'Gustav_Klimt', 'Hieronymus_Bosch', 'Kazimir_Malevich', 'Mikhail_Vrubel', 'Pablo_Picasso', 'Peter_Paul_Rubens', 'Pierre-Auguste_Renoir', 'Francisco_Goya', 'Frida_Kahlo', 'El_Greco', 'Albrecht_Dürer', 'Alfred_Sisley', 'Pieter_Bruegel', 'Marc_Chagall', 'Giotto_di_Bondone', 'Sandro_Botticelli', 'Caravaggio', 'Leonardo_da_Vinci', 'Diego_Velazquez', 'Henri_Matisse', 'Jan_van_Eyck', 'Edgar_Degas', 'Rembrandt', 'Titian', 'Henri_de_Toulouse-Lautrec', 'Gustave_Courbet', 'Camille_Pissarro', 'William_Turner', 'Edvard_Munch', 'Paul_Cezanne', 'Eugene_Delacroix', 'Henri_Rousseau', 'Georges_Seurat', 'Paul_Klee', 'Piet_Mondrian', 'Joan_Miro', 'Andy_Warhol', 'Paul_Gauguin', 'Raphael', 'Michelangelo', 'Jackson_Pollock']\n"
     ]
    }
   ],
   "source": [
    "#Acceder au csv\n",
    "\n",
    "dir = './art-challenge'\n",
    "path = os.path.join(dir, 'artists.csv')\n",
    "\n",
    "#Charger le csv\n",
    "\n",
    "artists_df = pd.read_csv(path) #df pour data frame\n",
    "\n",
    "#On va créer un dictionnaire {artist_name : index_associé}\n",
    "\n",
    "artists = artists_df[\"name\"].unique()\n",
    "\n",
    "def espaceReplacement(name): #On va remplacer les espaces par _ pour que ça correspondent au nom des file d'image\n",
    "    return ''.join(c if unicodedata.category(c) != 'Zs' else '_' for c in name)\n",
    "\n",
    "artists = [espaceReplacement(artist) for artist in artists] #La on a tous les artistes\n",
    "\n",
    "print(artists)\n",
    "\n",
    "artist_to_idx = {artist: idx for (idx, artist) in enumerate(artists)} #Voici le dictionnaire\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### on crée le dataset de toutes les images d'un folder, on leur donnera le label/index associé à l'artiste de l'image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArtDataset(Dataset):\n",
    "    def __init__(self, artist_to_idx, image_folder, transformation):\n",
    "        self.artist_to_idx = artist_to_idx\n",
    "        self.image_folder = image_folder\n",
    "        self.transformation = transformation\n",
    "        self.data = {} #dictionnaire { image_path: label/index_associé}\n",
    "        self.image_path= [] #on veut pouvoir garder les paths pour utiliser l'index dans __getitem__\n",
    "\n",
    "        for img_file in os.listdir(self.image_folder): #os.listdir(image_folder) liste tout les files dans image_folder \n",
    "            artist_name = img_file.rsplit('_',1)[0] #la on divise apres le dernier '_' \n",
    "            if artist_name in self.artist_to_idx:\n",
    "                label = self.artist_to_idx[artist_name]\n",
    "                img_path = os.path.join(self.image_folder, img_file)\n",
    "                self.data[img_path] = label\n",
    "                self.image_path.append(img_path)\n",
    "            else:\n",
    "                print(f\"Avertissement: '{artist_name}' ne se trouve pas dans ton dictionnaire\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.image_path[index]\n",
    "        label = self.data[img_path]\n",
    "        image = Image.open(img_path).convert('RGB') #On doit convertir en RGB car certaine image sont en niveau de gris (1 canal) et d'autre en couleur\n",
    "        if self.transformation:\n",
    "            image = self.transformation(image)\n",
    "        return image, label\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On va transformer les images, pour avoir des images de tailles uniforme mais aussi qui correspondent au standard utilisé par resNet50\n",
    "\n",
    "transformation = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Taille d'entrée ResNet50\n",
    "    transforms.ToTensor(),  #redim les valeurs de pixels de [0, 255] à [0, 1] et c'est les tenseurs sont les formats requis pour des réseaux de neuronnes Pytorch\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # Normalisation pour ResNet, Ces valeurs sont calculées à partir de la base de données ImageNet (sur laquelle ResNet est pré-entraîné)\n",
    "])\n",
    "\n",
    "lq_folder = './art-challenge/images_lq'\n",
    "dataset = ArtDataset(artist_to_idx, lq_folder , transformation)\n",
    "\n",
    "train_size = int(len(dataset)*0.7) #On prend 80% pour le training, Attention on peut pas prendre de float!\n",
    "val_size = int(len(dataset)*0.15)\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "train_dataset, val_dataset ,test_dataset = torch.utils.data.random_split(dataset, [train_size, val_size ,test_size])\n",
    "#La c'est des sous-ensemble du dataset initial \n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "#Plus besoin de shuffle ici vu que ça fait plus parti de l'entrainement du model\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[0.8789, 0.7933, 0.6563,  ..., 0.4337, 0.4851, 0.4337],\n",
      "         [0.6563, 0.6221, 0.6221,  ..., 0.1768, 0.2282, 0.2796],\n",
      "         [0.5193, 0.4508, 0.4337,  ..., 0.1426, 0.1083, 0.2282],\n",
      "         ...,\n",
      "         [0.8104, 0.6563, 0.6049,  ..., 0.8276, 0.8104, 0.8447],\n",
      "         [0.8618, 0.7419, 0.6906,  ..., 0.7933, 0.8104, 0.8789],\n",
      "         [0.8789, 0.7419, 0.6734,  ..., 0.8104, 0.8789, 0.8961]],\n",
      "\n",
      "        [[1.0280, 0.9405, 0.8004,  ..., 0.5728, 0.6254, 0.5728],\n",
      "         [0.8004, 0.7654, 0.7654,  ..., 0.3102, 0.3627, 0.4153],\n",
      "         [0.6604, 0.5903, 0.5728,  ..., 0.2752, 0.2402, 0.3627],\n",
      "         ...,\n",
      "         [0.9580, 0.8004, 0.7479,  ..., 0.9755, 0.9580, 0.9930],\n",
      "         [1.0105, 0.8880, 0.8354,  ..., 0.9405, 0.9580, 1.0280],\n",
      "         [1.0280, 0.8880, 0.8179,  ..., 0.9580, 1.0280, 1.0455]],\n",
      "\n",
      "        [[1.2457, 1.1585, 1.0191,  ..., 0.7925, 0.8448, 0.7925],\n",
      "         [1.0191, 0.9842, 0.9842,  ..., 0.5311, 0.5834, 0.6356],\n",
      "         [0.8797, 0.8099, 0.7925,  ..., 0.4962, 0.4614, 0.5834],\n",
      "         ...,\n",
      "         [1.1759, 1.0191, 0.9668,  ..., 1.1934, 1.1759, 1.2108],\n",
      "         [1.2282, 1.1062, 1.0539,  ..., 1.1585, 1.1759, 1.2457],\n",
      "         [1.2457, 1.1062, 1.0365,  ..., 1.1759, 1.2457, 1.2631]]]), 19)\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0]) #parfait, l'index 19 correspond bien a Dürer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### On a récupéré les dataloader, on les utilisera durant la phase d'entrainement et de test\n",
    "\n",
    "#### Il faut maintenant chargé le modèle resnet50 pré-entrainé et changer la derniere couche pour qu'elle correspondent au nombre d'artiste dans notre csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet50(weights='DEFAULT') #On charge le modèle\n",
    "\n",
    "avant_derniere_couche = model.fc.in_features #On recup la taille de l'avant derniere couche\n",
    "model.fc = nn.Linear(avant_derniere_couche, len(artists)) #On a change la derniere couche\n",
    "\n",
    "#A partir de la on va commencer a entrainer donc on place le device dans cuda pour utiliser le gpu\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device) #On déplace le modèle dedans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#On regarde si on est bien sur le gpu\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimize = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "def training(num_epochs, model, criterion,optimizer):\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_train_loss= []\n",
    "        t = tqdm(train_loader)\n",
    "        for image, label in t:\n",
    "            image, label = image.to(device), label.to(device)\n",
    "            outputs = model(image)\n",
    "            loss = criterion(outputs, label)\n",
    "\n",
    "            optimizer.zero_grad() #on remet a zero les gradients pour pas que ça s'accumule\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_train_loss.append(loss.item())\n",
    "\n",
    "        avg_train_loss = sum(total_train_loss)/ len(train_loader)\n",
    "\n",
    "        model.eval()\n",
    "        total_val_loss = []\n",
    "        correct = 0\n",
    "        with torch.no_grad(): #Permet de ne plus mettre a jour les poids \n",
    "            for image, label in val_loader:\n",
    "                image, label = image.to(device), label.to(device)\n",
    "                outputs = model(image)\n",
    "                val_loss = criterion(outputs, label)\n",
    "                _, predicted = torch.max(outputs,1) #permet d'obtenir quelle classe la plus grande proba, donc quelle a ete la prediction\n",
    "                correct += (predicted == label).sum().item() #?\n",
    "                total_val_loss.append(val_loss.item())\n",
    "\n",
    "        avg_val_loss = sum(total_val_loss)/len(val_loader)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {avg_train_loss:.4f}, Avg Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "    total_test_loss=[]\n",
    "    correct_test = 0\n",
    "    total_test=0\n",
    "    with torch.no_grad():\n",
    "        for image,label in test_loader:\n",
    "            image, label = image.to(device), label.to(device)\n",
    "            outputs = model(image)\n",
    "            test_loss = criterion(outputs, label)\n",
    "            _, predicted_test = torch.max(outputs, 1)\n",
    "            correct_test += (predicted_test == label).sum().item()\n",
    "            total_test_loss.append(test_loss.item())\n",
    "            total_test += label.size(0)\n",
    "\n",
    "    avg_test_loss = sum(total_test_loss)/len(test_loader)\n",
    "    accuracy = correct_test/total_test*100\n",
    "    print(f\"Test Loss: {avg_test_loss:.4f}, test Accuracy: {accuracy:.4f} \")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 183/183 [01:53<00:00,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 0.1404, Avg Val Loss: 1.4788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 183/183 [01:52<00:00,  1.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Train Loss: 0.0851, Avg Val Loss: 1.8157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 183/183 [01:56<00:00,  1.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Train Loss: 0.0749, Avg Val Loss: 2.3081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 183/183 [01:54<00:00,  1.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Train Loss: 0.0989, Avg Val Loss: 1.9172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 183/183 [01:53<00:00,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Train Loss: 0.0762, Avg Val Loss: 1.6831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 183/183 [01:52<00:00,  1.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Train Loss: 0.0795, Avg Val Loss: 1.5242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 183/183 [01:54<00:00,  1.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Train Loss: 0.0454, Avg Val Loss: 1.5140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 183/183 [01:54<00:00,  1.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Train Loss: 0.0521, Avg Val Loss: 1.7221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 183/183 [01:56<00:00,  1.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Train Loss: 0.0712, Avg Val Loss: 1.9549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 183/183 [01:55<00:00,  1.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Train Loss: 0.0597, Avg Val Loss: 1.4783\n",
      "Test Loss: 1.3721, test Accuracy: 69.3780 \n"
     ]
    }
   ],
   "source": [
    "training(10, model, criterion, optimize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Les prochaines ameliorations possible sont soit de faire de la data augmentation pour homogénéïsé le nombre d'image pour chaque artiste\n",
    "### ou bien on peut trouver un moyen d'utiliser les autres données dans notre csv comme la biographie des auteurs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### On commence par la 2eme amelioration ( ajouter de nouvelles caractéristiques). ON les ajoutes directement a notre pipeline ArtDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 0, 'years': '1884 - 1920', 'genre': 'Expressionism', 'nationality': 'Italian', 'bio': \"Amedeo Clemente Modigliani (Italian pronunciation: [ameˈdɛːo modiʎˈʎaːni]; 12 July 1884 – 24 January 1920) was an Italian Jewish painter and sculptor who worked mainly in France. He is known for portraits and nudes in a modern style characterized by elongation of faces, necks, and figures that were not received well during his lifetime but later found acceptance. Modigliani spent his youth in Italy, where he studied the art of antiquity and the Renaissance. In 1906 he moved to Paris, where he came into contact with such artists as Pablo Picasso and Constantin Brâncuși. By 1912 Modigliani was exhibiting highly stylized sculptures with Cubists of the Section d'Or group at the Salon d'Automne.\", 'wikipedia': 'http://en.wikipedia.org/wiki/Amedeo_Modigliani', 'paintings': 193}\n",
      "['Amedeo_Modigliani', 'Vasiliy_Kandinskiy', 'Diego_Rivera', 'Claude_Monet', 'Rene_Magritte', 'Salvador_Dali', 'Edouard_Manet', 'Andrei_Rublev', 'Vincent_van_Gogh', 'Gustav_Klimt', 'Hieronymus_Bosch', 'Kazimir_Malevich', 'Mikhail_Vrubel', 'Pablo_Picasso', 'Peter_Paul_Rubens', 'Pierre-Auguste_Renoir', 'Francisco_Goya', 'Frida_Kahlo', 'El_Greco', 'Albrecht_Dürer', 'Alfred_Sisley', 'Pieter_Bruegel', 'Marc_Chagall', 'Giotto_di_Bondone', 'Sandro_Botticelli', 'Caravaggio', 'Leonardo_da_Vinci', 'Diego_Velazquez', 'Henri_Matisse', 'Jan_van_Eyck', 'Edgar_Degas', 'Rembrandt', 'Titian', 'Henri_de_Toulouse-Lautrec', 'Gustave_Courbet', 'Camille_Pissarro', 'William_Turner', 'Edvard_Munch', 'Paul_Cezanne', 'Eugene_Delacroix', 'Henri_Rousseau', 'Georges_Seurat', 'Paul_Klee', 'Piet_Mondrian', 'Joan_Miro', 'Andy_Warhol', 'Paul_Gauguin', 'Raphael', 'Michelangelo', 'Jackson_Pollock']\n"
     ]
    }
   ],
   "source": [
    "#On va dabord rajouter les données additionelle dans un nouveau dictionnaire\n",
    "\n",
    "dir = './art-challenge/'\n",
    "path = os.path.join(dir, 'artists.csv')\n",
    "\n",
    "artist_df_2 = pd.read_csv(path)\n",
    "\n",
    "additional_data = artist_df_2.set_index(\"name\").T.to_dict() #utilise la colonne \"name\" comme index, chq artiste devient un clé\n",
    "#T.to_dict() transpose le dataframe pour que chaque ligne devienne un dictionnaire de donnée par artiste\n",
    "\n",
    "#On l'affiche pour voir si ça ressemble a ce qu'on veut\n",
    "\n",
    "print(additional_data['Amedeo Modigliani'])\n",
    "\n",
    "#OK c'est bon \n",
    "\n",
    "artists_df = pd.read_csv(path) #df pour data frame\n",
    "\n",
    "#On va créer un dictionnaire {artist_name : index_associé}\n",
    "\n",
    "artists = artists_df[\"name\"].unique()\n",
    "\n",
    "def espaceReplacement(name): #On va remplacer les espaces par _ pour que ça correspondent au nom des file d'image\n",
    "    return ''.join(c if unicodedata.category(c) != 'Zs' else '_' for c in name)\n",
    "\n",
    "artists = [espaceReplacement(artist) for artist in artists] #La on a tous les artistes\n",
    "\n",
    "print(artists)\n",
    "\n",
    "artist_to_idx = {artist: idx for (idx, artist) in enumerate(artists)} #Voici le dictionnaire\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArtDatasetv2(Dataset):\n",
    "    def __init__(self, image_folder, artist_to_idx, transformation, additional_data):\n",
    "        self.image_folder = image_folder\n",
    "        self.artist_to_idx = artist_to_idx\n",
    "        self.transformation = transformation\n",
    "        self.additional_data = additional_data\n",
    "        self.data = {}\n",
    "        self.image_path = []\n",
    "\n",
    "        for img_file in os.listdir(self.image_folder):\n",
    "            artist_name = img_file.rsplit('_', 1)[0]\n",
    "            if artist_name in self.artist_to_idx:\n",
    "                artist_name_nospace = artist_name.replace('_', ' ')\n",
    "                label = self.artist_to_idx[artist_name]\n",
    "                img_path = os.path.join(self.image_folder, img_file)\n",
    "                additional_info = self.additional_data.get(artist_name_nospace, {})\n",
    "\n",
    "                # Ajouter toutes les informations supplémentaires à `self.data`\n",
    "                self.data[img_path] = {\n",
    "                    \"label\": label,\n",
    "                    \"years\": additional_info.get(\"years\", \"Unknown\"),\n",
    "                    \"genre\": additional_info.get(\"genre\", \"Unknown\"),\n",
    "                    \"nationality\": additional_info.get(\"nationality\", \"Unknown\"),\n",
    "                    \"bio\": additional_info.get(\"bio\", \"Unknown\"),\n",
    "                    \"wikipedia\": additional_info.get(\"wikipedia\", \"Unknown\"),\n",
    "                    \"paintings\": additional_info.get(\"paintings\", \"Unknown\")\n",
    "                }\n",
    "                self.image_path.append(img_path)\n",
    "            else:\n",
    "                print(f\"Avertissement : '{artist_name}' n'est pas dans artist_to_idx\")\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.image_path[index]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        if self.transformation:\n",
    "            image = self.transformation(image)\n",
    "        \n",
    "        # Récupérer toutes les informations stockées dans `self.data`\n",
    "        data_info = self.data[img_path]\n",
    "\n",
    "        label = data_info[\"label\"]\n",
    "        years = data_info[\"years\"]\n",
    "        genre = data_info[\"genre\"]\n",
    "        nationality = data_info[\"nationality\"]\n",
    "        bio = data_info[\"bio\"]\n",
    "        wikipedia = data_info[\"wikipedia\"]\n",
    "        paintings = data_info[\"paintings\"]\n",
    "\n",
    "        return image, label, years, genre, nationality, bio, wikipedia, paintings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[0.8789, 0.7933, 0.6563,  ..., 0.4337, 0.4851, 0.4337],\n",
      "         [0.6563, 0.6221, 0.6221,  ..., 0.1768, 0.2282, 0.2796],\n",
      "         [0.5193, 0.4508, 0.4337,  ..., 0.1426, 0.1083, 0.2282],\n",
      "         ...,\n",
      "         [0.8104, 0.6563, 0.6049,  ..., 0.8276, 0.8104, 0.8447],\n",
      "         [0.8618, 0.7419, 0.6906,  ..., 0.7933, 0.8104, 0.8789],\n",
      "         [0.8789, 0.7419, 0.6734,  ..., 0.8104, 0.8789, 0.8961]],\n",
      "\n",
      "        [[1.0280, 0.9405, 0.8004,  ..., 0.5728, 0.6254, 0.5728],\n",
      "         [0.8004, 0.7654, 0.7654,  ..., 0.3102, 0.3627, 0.4153],\n",
      "         [0.6604, 0.5903, 0.5728,  ..., 0.2752, 0.2402, 0.3627],\n",
      "         ...,\n",
      "         [0.9580, 0.8004, 0.7479,  ..., 0.9755, 0.9580, 0.9930],\n",
      "         [1.0105, 0.8880, 0.8354,  ..., 0.9405, 0.9580, 1.0280],\n",
      "         [1.0280, 0.8880, 0.8179,  ..., 0.9580, 1.0280, 1.0455]],\n",
      "\n",
      "        [[1.2457, 1.1585, 1.0191,  ..., 0.7925, 0.8448, 0.7925],\n",
      "         [1.0191, 0.9842, 0.9842,  ..., 0.5311, 0.5834, 0.6356],\n",
      "         [0.8797, 0.8099, 0.7925,  ..., 0.4962, 0.4614, 0.5834],\n",
      "         ...,\n",
      "         [1.1759, 1.0191, 0.9668,  ..., 1.1934, 1.1759, 1.2108],\n",
      "         [1.2282, 1.1062, 1.0539,  ..., 1.1585, 1.1759, 1.2457],\n",
      "         [1.2457, 1.1062, 1.0365,  ..., 1.1759, 1.2457, 1.2631]]]), 19, '1471 - 1528', 'Northern Renaissance', 'German', 'Albrecht Dürer (; German: [ˈʔalbʁɛçt ˈdyːʁɐ]; 21 May 1471 – 6 April 1528) sometimes spelt in English as Durer or Duerer, without umlaut, was a painter, printmaker, and theorist of the German Renaissance. Born in Nuremberg, Dürer established his reputation and influence across Europe when he was still in his twenties due to his high-quality woodcut prints.', 'http://en.wikipedia.org/wiki/Albrecht_Dürer', 328)\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "lq_folder = './art-challenge/images_lq'\n",
    "\n",
    "transformation = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Taille d'entrée ResNet50\n",
    "    transforms.ToTensor(),  #redim les valeurs de pixels de [0, 255] à [0, 1] et c'est les tenseurs sont les formats requis pour des réseaux de neuronnes Pytorch\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # Normalisation pour ResNet, Ces valeurs sont calculées à partir de la base de données ImageNet (sur laquelle ResNet est pré-entraîné)\n",
    "])\n",
    "\n",
    "lq_folder = './art-challenge/images_lq'\n",
    "\n",
    "dataset = ArtDatasetv2(\n",
    "    image_folder=lq_folder,\n",
    "    artist_to_idx=artist_to_idx,\n",
    "    transformation=transformation,\n",
    "    additional_data=additional_data\n",
    ")\n",
    "\n",
    "# Créez le DataLoader\n",
    "train_size = int(len(dataset)*0.7) #On prend 80% pour le training, Attention on peut pas prendre de float!\n",
    "val_size = int(len(dataset)*0.15)\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "train_dataset, val_dataset ,test_dataset = torch.utils.data.random_split(dataset, [train_size, val_size ,test_size])\n",
    "#La c'est des sous-ensemble du dataset initial \n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "#Plus besoin de shuffle ici vu que ça fait plus parti de l'entrainement du model\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Maintenant il faut réussir a intégrer ces nouvelles données au model. Il faut pouvoir traiter les données textuel, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va combiner ResNet50 qui va combiner les caractéristiques extraites des images\n",
    "et un réseau dense pour les données additionnelles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetWithAdditionalData(nn.Module):\n",
    "    def __init__(self, num_classes, additional_data_size):\n",
    "        super(ResNetWithAdditionalData, self).__init__()\n",
    "        # Charger ResNet50 préentraîné sans la dernière couche\n",
    "        self.resnet = models.resnet50(weights='DEFAULT')\n",
    "        num_ftrs = self.resnet.fc.in_features\n",
    "        self.resnet.fc = nn.Identity()  # On remplace la dernière couche par une identité pck on doit encore la combiner avec les data_additionnelle\n",
    "\n",
    "        # Réseau dense pour les données additionnelles\n",
    "        self.additional_data_net = nn.Sequential(\n",
    "            nn.Linear(additional_data_size, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # Couche finale de classification\n",
    "        self.fc = nn.Linear(num_ftrs + 64, num_classes)\n",
    "\n",
    "    def forward(self, image, additional_data):\n",
    "        # Passer l'image dans ResNet\n",
    "        image_features = self.resnet(image)\n",
    "        \n",
    "        # Passer les données additionnelles dans le réseau dense\n",
    "        additional_features = self.additional_data_net(additional_data)\n",
    "        \n",
    "        # Concaténer les sorties\n",
    "        combined_features = torch.cat((image_features, additional_features), dim=1)\n",
    "        \n",
    "        # Passer à travers la couche de classification\n",
    "        outputs = self.fc(combined_features)\n",
    "\n",
    "        return outputs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taille des données additionnelles (vous devez calculer la taille totale des entrées)\n",
    "additional_data_size = 6\n",
    "num_classes = len(artists)\n",
    "\n",
    "# Instanciation du modèle\n",
    "model = ResNetWithAdditionalData(num_classes=num_classes, additional_data_size=additional_data_size)\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(num_epochs, model, criterion, optimizer):\n",
    "        #Initialisation des encoders\n",
    "    years_encoder = LabelEncoder()\n",
    "    genre_encoder = LabelEncoder()\n",
    "    nationality_encoder = LabelEncoder()\n",
    "    bio_encoder = LabelEncoder()\n",
    "    wikipedia_encoder = LabelEncoder()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_train_loss = []\n",
    "        t = tqdm(train_loader)\n",
    "        \n",
    "        for image, label, years, genre, nationality, bio, wikipedia, paintings in t:\n",
    "            # Déplacez les données sur le bon device\n",
    "            image, label = image.to(device), label.to(device)\n",
    "\n",
    "            #On doit convertir la data supplémentaire en tensor mais pour ça il faut changer les chaine de caractère en float, sinon on peut pas transformer en tenseur\n",
    "\n",
    "            # Convertir les tuples en entiers\n",
    "            years_encoded = years_encoder.fit_transform(years)\n",
    "            genre_encoded = genre_encoder.fit_transform(genre)\n",
    "            nationality_encoded = nationality_encoder.fit_transform(nationality)\n",
    "            bio_encoded = bio_encoder.fit_transform(bio)\n",
    "            wikipedia_encoded = wikipedia_encoder.fit_transform(wikipedia)\n",
    "\n",
    "            # Convertir en tensors\n",
    "            years_encoded = torch.tensor(years_encoded).float()\n",
    "            genre_encoded = torch.tensor(genre_encoded).float()\n",
    "            nationality_encoded = torch.tensor(nationality_encoded).float()\n",
    "            bio_encoded = torch.tensor(bio_encoded).float()\n",
    "            wikipedia_encoded = torch.tensor(wikipedia_encoded).float()\n",
    "\n",
    "            additional_data = torch.stack([years_encoded,genre_encoded, nationality_encoded, bio_encoded, wikipedia_encoded, paintings], dim=1).to(device)            \n",
    "            # Passer à travers le modèle\n",
    "            outputs = model(image, additional_data)\n",
    "            loss = criterion(outputs, label)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_train_loss.append(loss.item())\n",
    "\n",
    "        avg_train_loss = sum(total_train_loss) / len(train_loader)\n",
    "\n",
    "        # Évaluation du modèle\n",
    "        model.eval()\n",
    "        total_val_loss = []\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for image, label, years, genre, nationality, bio, wikipedia, paintings in val_loader:\n",
    "                image, label = image.to(device), label.to(device)\n",
    "\n",
    "                # Convertir les tuples en entiers\n",
    "                years_encoded = years_encoder.fit_transform(years)\n",
    "                genre_encoded = genre_encoder.fit_transform(genre)\n",
    "                nationality_encoded = nationality_encoder.fit_transform(nationality)\n",
    "                bio_encoded = bio_encoder.fit_transform(bio)\n",
    "                wikipedia_encoded = wikipedia_encoder.fit_transform(wikipedia)\n",
    "\n",
    "                # Convertir en tensors\n",
    "                years_encoded = torch.tensor(years_encoded).float()\n",
    "                genre_encoded = torch.tensor(genre_encoded).float()\n",
    "                nationality_encoded = torch.tensor(nationality_encoded).float()\n",
    "                bio_encoded = torch.tensor(bio_encoded).float()\n",
    "                wikipedia_encoded = torch.tensor(wikipedia_encoded).float()\n",
    "\n",
    "                additional_data = torch.stack([years_encoded,genre_encoded, nationality_encoded, bio_encoded, wikipedia_encoded, paintings], dim=1).to(device)            \n",
    "\n",
    "                outputs = model(image, additional_data)\n",
    "                val_loss = criterion(outputs, label)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                correct += (predicted == label).sum().item()\n",
    "                total_val_loss.append(val_loss.item())\n",
    "\n",
    "        avg_val_loss = sum(total_val_loss) / len(val_loader)\n",
    "        accuracy = correct / len(val_loader.dataset) * 100\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {avg_train_loss:.4f}, Avg Val Loss: {avg_val_loss:.4f}, Val Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "    # Test final\n",
    "    model.eval()\n",
    "    total_test_loss = []\n",
    "    correct_test = 0\n",
    "    total_test = 0\n",
    "    with torch.no_grad():\n",
    "        for image, label, years, genre, nationality, bio, wikipedia, paintings in test_loader:\n",
    "            image, label = image.to(device), label.to(device)\n",
    "\n",
    "            # Convertir les tuples en entiers\n",
    "            years_encoded = years_encoder.fit_transform(years)\n",
    "            genre_encoded = genre_encoder.fit_transform(genre)\n",
    "            nationality_encoded = nationality_encoder.fit_transform(nationality)\n",
    "            bio_encoded = bio_encoder.fit_transform(bio)\n",
    "            wikipedia_encoded = wikipedia_encoder.fit_transform(wikipedia)\n",
    "\n",
    "            # Convertir en tensors\n",
    "            years_encoded = torch.tensor(years_encoded).float()\n",
    "            genre_encoded = torch.tensor(genre_encoded).float()\n",
    "            nationality_encoded = torch.tensor(nationality_encoded).float()\n",
    "            bio_encoded = torch.tensor(bio_encoded).float()\n",
    "            wikipedia_encoded = torch.tensor(wikipedia_encoded).float()\n",
    "\n",
    "            additional_data = torch.stack([years_encoded,genre_encoded, nationality_encoded, bio_encoded, wikipedia_encoded, paintings], dim=1).to(device)            \n",
    "\n",
    "\n",
    "            additional_data = torch.stack([years, genre, nationality, bio, wikipedia, paintings], dim=1).float().to(device)\n",
    "            \n",
    "            outputs = model(image, additional_data)\n",
    "            test_loss = criterion(outputs, label)\n",
    "            _, predicted_test = torch.max(outputs, 1)\n",
    "            correct_test += (predicted_test == label).sum().item()\n",
    "            total_test_loss.append(test_loss.item())\n",
    "            total_test += label.size(0)\n",
    "\n",
    "    avg_test_loss = sum(total_test_loss) / len(test_loader)\n",
    "    accuracy = correct_test / total_test * 100\n",
    "    print(f\"Test Loss: {avg_test_loss:.4f}, Test Accuracy: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 5/183 [00:50<30:00, 10.12s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[0;32m      2\u001b[0m optimize \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mtraining\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[40], line 43\u001b[0m, in \u001b[0;36mtraining\u001b[1;34m(num_epochs, model, criterion, optimizer)\u001b[0m\n\u001b[0;32m     40\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     41\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m---> 43\u001b[0m     total_train_loss\u001b[38;5;241m.\u001b[39mappend(\u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     45\u001b[0m avg_train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(total_train_loss) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# Évaluation du modèle\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimize = optim.Adam(model.parameters(), lr=0.001)\n",
    "training(10, model, criterion, optimize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
